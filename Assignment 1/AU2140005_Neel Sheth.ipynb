{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing testcases\\testcase-1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.409587 to fit\n",
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.409587 to fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing testcases\\testcase-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.814877 to fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing testcases\\testcase-3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.714392 to fit\n",
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.409587 to fit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import graphviz\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# Function to load NFA from the input.txt file\n",
    "def load_nfa(input_file):\n",
    "    nfa = {\n",
    "        'states': set(),\n",
    "        'alphabet': set(),\n",
    "        'transitions': defaultdict(dict),\n",
    "        'start_state': None,\n",
    "        'accept_states': set()\n",
    "    }\n",
    "\n",
    "    # Open the file and parse each line\n",
    "    with open(input_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith(\"States:\"):\n",
    "                # Extract states from the file (removing the braces and splitting by commas)\n",
    "                nfa['states'] = set(line.split(\":\")[1].strip().strip('{}').split(\", \"))\n",
    "\n",
    "            elif line.startswith(\"Alphabet:\"):\n",
    "                # Extract the alphabet (input symbols) from the file\n",
    "                nfa['alphabet'] = set(line.split(\":\")[1].strip().strip('{}').split(\", \"))\n",
    "\n",
    "            elif line.startswith(\"Start State:\"):\n",
    "                # Define the starting state\n",
    "                nfa['start_state'] = line.split(\":\")[1].strip()\n",
    "\n",
    "            elif line.startswith(\"Accept States:\"):\n",
    "                # Identify the accept states, removing any braces\n",
    "                nfa['accept_states'] = set(line.split(\":\")[1].strip().strip('{}').split(\", \"))\n",
    "\n",
    "            elif line.startswith(\"Transitions:\"):\n",
    "                # Parse the transitions, formatted as 'state -> symbol -> next_states'\n",
    "                for transition in file:\n",
    "                    transition = transition.strip()\n",
    "                    if \"->\" in transition:\n",
    "                        state, symbol, next_states = transition.split(\"->\")\n",
    "                        state = state.strip()\n",
    "                        symbol = symbol.strip()\n",
    "                        next_states = next_states.strip().split(\", \")\n",
    "\n",
    "                        # Store the transitions for the NFA\n",
    "                        nfa['transitions'].setdefault(state, {}).setdefault(symbol, []).extend(next_states)\n",
    "    \n",
    "    return nfa\n",
    "\n",
    "# Function to convert an NFA to a DFA using the Powerset Construction method\n",
    "def nfa_to_dfa(nfa):\n",
    "    dfa = {\n",
    "        'states': set(),\n",
    "        'alphabet': nfa['alphabet'],\n",
    "        'transitions': defaultdict(dict),\n",
    "        'start_state': None,\n",
    "        'accept_states': set()\n",
    "    }\n",
    "\n",
    "    # The initial state of the DFA is the set containing the NFA's start state\n",
    "    start_state = frozenset([nfa['start_state']])\n",
    "    dfa['start_state'] = str(start_state)  # Convert set to string for naming consistency\n",
    "    dfa['states'].add(str(start_state))\n",
    "\n",
    "    # Initialize a queue to explore new DFA states\n",
    "    queue = deque([start_state])\n",
    "    visited = set([str(start_state)])\n",
    "\n",
    "    while queue:\n",
    "        current_dfa_state = queue.popleft()\n",
    "\n",
    "        for symbol in nfa['alphabet']:\n",
    "            next_nfa_states = set()\n",
    "            # Determine which NFA states can be reached from current DFA state on each symbol\n",
    "            for nfa_state in current_dfa_state:\n",
    "                if symbol in nfa['transitions'].get(nfa_state, {}):\n",
    "                    next_nfa_states.update(nfa['transitions'][nfa_state][symbol])\n",
    "\n",
    "            # Create a new DFA state corresponding to the set of reachable NFA states\n",
    "            next_dfa_state = frozenset(next_nfa_states)\n",
    "            next_dfa_state_str = str(next_dfa_state)  # Use string representation for consistency\n",
    "\n",
    "            if next_dfa_state:\n",
    "                dfa['transitions'][str(current_dfa_state)][symbol] = next_dfa_state_str\n",
    "                if next_dfa_state_str not in visited:\n",
    "                    visited.add(next_dfa_state_str)\n",
    "                    queue.append(next_dfa_state)\n",
    "                    dfa['states'].add(next_dfa_state_str)\n",
    "\n",
    "            # Mark a DFA state as an accept state if any corresponding NFA states are accept states\n",
    "            if any(state in nfa['accept_states'] for state in next_nfa_states):\n",
    "                dfa['accept_states'].add(next_dfa_state_str)\n",
    "\n",
    "    return dfa\n",
    "\n",
    "# Function to minimize a DFA\n",
    "def minimize_dfa(dfa):\n",
    "    # Initial partition: separate accepting and non-accepting states\n",
    "    P = [dfa['accept_states'], dfa['states'] - dfa['accept_states']]\n",
    "    W = [dfa['accept_states'].copy()]  # Subset of states that need further examination\n",
    "\n",
    "    # Refine partitions based on transitions\n",
    "    while W:\n",
    "        A = W.pop()\n",
    "\n",
    "        for symbol in dfa['alphabet']:\n",
    "            # Identify states that can transition on 'symbol' to a state in 'A'\n",
    "            X = {state for state in dfa['states'] if symbol in dfa['transitions'].get(state, {}) and dfa['transitions'][state][symbol] in A}\n",
    "\n",
    "            for Y in P[:]:\n",
    "                intersection = Y & X\n",
    "                difference = Y - X\n",
    "\n",
    "                if intersection and difference:\n",
    "                    # Split partition Y into two: intersection and difference\n",
    "                    P.remove(Y)\n",
    "                    P.append(intersection)\n",
    "                    P.append(difference)\n",
    "\n",
    "                    # Add the smaller subset to W\n",
    "                    if intersection in W:\n",
    "                        W.append(difference)\n",
    "                    else:\n",
    "                        W.append(intersection)\n",
    "\n",
    "    # Create minimized DFA\n",
    "    minimized_dfa = {\n",
    "        'states': set(),\n",
    "        'alphabet': dfa['alphabet'],\n",
    "        'transitions': defaultdict(dict),\n",
    "        'start_state': None,\n",
    "        'accept_states': set()\n",
    "    }\n",
    "\n",
    "    # Map old DFA states to new DFA states based on partitions\n",
    "    state_map = {}\n",
    "    for partition in P:\n",
    "        new_state = str(frozenset(partition))  # Use string representation for consistency\n",
    "        minimized_dfa['states'].add(new_state)\n",
    "\n",
    "        for state in partition:\n",
    "            state_map[state] = new_state\n",
    "            if state == dfa['start_state']:\n",
    "                minimized_dfa['start_state'] = new_state\n",
    "            if state in dfa['accept_states']:\n",
    "                minimized_dfa['accept_states'].add(new_state)\n",
    "\n",
    "    # Define transitions for the minimized DFA\n",
    "    for old_state, transitions in dfa['transitions'].items():\n",
    "        new_state = state_map[old_state]\n",
    "        for symbol, next_old_state in transitions.items():\n",
    "            minimized_dfa['transitions'][new_state][symbol] = state_map[next_old_state]\n",
    "\n",
    "    return minimized_dfa\n",
    "\n",
    "# Function to create and render a graph representation of an automaton\n",
    "def draw_graph(automaton, output_file):\n",
    "    dot = graphviz.Digraph()\n",
    "    \n",
    "    # Set graph size and resolution\n",
    "    dot.attr(size='100,200', dpi='800')\n",
    "    \n",
    "    # Add nodes with double circles for accept states\n",
    "    for state in automaton.get('states', []):\n",
    "        if state in automaton.get('accept_states', []):\n",
    "            dot.node(state, shape='doublecircle')\n",
    "        else:\n",
    "            dot.node(state, shape='circle')\n",
    "    \n",
    "    # Add edges based on transitions\n",
    "    for state, transitions in automaton.get('transitions', {}).items():\n",
    "        for symbol, next_states in transitions.items():\n",
    "            for next_state in next_states:\n",
    "                dot.edge(state, next_state, label=symbol)\n",
    "    \n",
    "    # Save the graph as a PNG image\n",
    "    dot.render(output_file, format='png', cleanup=True)\n",
    "\n",
    "# Function to handle a single test case\n",
    "def handle_testcase(testcase_dir):\n",
    "    input_file = os.path.join(testcase_dir, 'input.txt')\n",
    "    dfa_output_file = os.path.join(testcase_dir, 'dfa_image')\n",
    "    minimized_dfa_output_file = os.path.join(testcase_dir, 'minimized_dfa_image')\n",
    "\n",
    "    # Load NFA from the file\n",
    "    nfa = load_nfa(input_file)\n",
    "    \n",
    "    # Convert the NFA to a DFA\n",
    "    dfa = nfa_to_dfa(nfa)\n",
    "    \n",
    "    # Create the DFA graph image\n",
    "    draw_graph(dfa, dfa_output_file)\n",
    "\n",
    "    # Minimize the DFA\n",
    "    minimized_dfa = minimize_dfa(dfa)\n",
    "    \n",
    "    # Create the minimized DFA graph image\n",
    "    draw_graph(minimized_dfa, minimized_dfa_output_file)\n",
    "\n",
    "# Process all test cases in the given directory\n",
    "def handle_all_testcases(testcases_root):\n",
    "    for testcase in os.listdir(testcases_root):\n",
    "        testcase_dir = os.path.join(testcases_root, testcase)\n",
    "        if os.path.isdir(testcase_dir):\n",
    "            print(f\"Processing {testcase_dir}...\")\n",
    "            handle_testcase(testcase_dir)\n",
    "\n",
    "# Entry point for running the script\n",
    "if __name__ == \"__main__\":\n",
    "    handle_all_testcases('testcases')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
